{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0daf253a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ef2c2034676875dd678d3773e7e92b3",
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2023) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Leila Malihi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4b156",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac582d5001c9669f006e7190d2ff2030",
     "grade": false,
     "grade_id": "cell-175c5b8f652e026d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise Sheet 02: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f0848",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa7f2b92e10e5db5ff4903ad50cf24d2",
     "grade": false,
     "grade_id": "cell-0779efa0bccb27ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "By now everyone should have found a group. If someone still has none but wants to participate in the course please contact one of the tutors.\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Sunday, April 30th, 2023**. If you need help (and Google and other resources were not enough), please use the StudIP forum or contact your groups designated tutor or whom ever of us you run into first. Please upload your results to your group's studip folder.\n",
    "\n",
    "As next Monday is a public holiday, there will be **no feedback sessions with your tutor** (neither on Monday nor on Tuesday). Nevertheless, upload your solutions to StudIP so that the tutors can check them. We will discuss this sheet in the practice session on Tuesday, May 2nd, so please be prepared to present your solutions (or questions) in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6662ea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16b7327c168b66662f21312fefa412ff",
     "grade": false,
     "grade_id": "math-euclid",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Math recap (Euclidean Space) [0 Points]\n",
    "\n",
    "This exercise is supposed to be very easy and is voluntary. There will be a similar exercise on every sheet.\n",
    "It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them.\n",
    "Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up again. You are always welcome to discuss questions with the tutors or in the practice session.\n",
    "Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50de42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "899ac70855dbd336b6edef96c4c1a6f5",
     "grade": false,
     "grade_id": "math-euclid-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is a *Euclidean space*? What is the *Cartesian plane*? How are they usually denoted? How to write points in these spaces?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae34be98",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10da800d32483f0d4bfa9cf43624b3c0",
     "grade": true,
     "grade_id": "math-euclid-a1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The Euclidean space describes the view of the world for a late perspective. This is important as one can say that the angels inside of a trinages have to add up to 180. This must not be the case in other math spaces.\n",
    "\n",
    "The Cartesian plan is known mostly from normal coordinate system. A point in sapce is dentoted by staing the values of each repesented dimention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97713a5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bf071a4c6d1ff977bcd336eb96d7daa",
     "grade": false,
     "grade_id": "math-euclid-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is the *norm* of a vector in a Euclidean space? How to *add* and *substract* two vectors? How is the *Euclidean distance* defined? Are there other ways to measure distances?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e768e5e6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f95335b2228d0766f6bdbbba83f857d",
     "grade": true,
     "grade_id": "math-euclid-a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "A Vectore is generelly defined with the cordinates of the end of the vectore form the starting point (1;1;1) vor example\n",
    "\n",
    "If you want to add to an vectore you just add the values of the second value onto the values of the first vector. the same hold for substraction\n",
    "\n",
    "Disctance: d = sqrt((x2 - x1)^2 + (y2 - y1)^2 + (z2 - z1)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce414012",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7a7304a941a4864f1c0ad2cce2d86b3",
     "grade": false,
     "grade_id": "math-euclid-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** What is the (standard) *scalar product* of two vectors? How is it related to the length and angle between these vectors? Name some use cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89f89fdd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5c2f82430f4ba30219c7b0e9a43836d",
     "grade": true,
     "grade_id": "math-euclid-a3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The scarlar product of two vecotrs represents the angle between them. if we have to vectores A = (a,b,c) and B = (d,e,f) the scarlarprodcut would be A.B = (a*d) + (b*e) + (c*f)\n",
    "\n",
    "If the scarlar product is 0 then the vectors lien in a 90degrees andgle to eachother\n",
    "\n",
    "If it is positive the angle is less than 90 degrees\n",
    "\n",
    "if its negative than it is bigger than 90 degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1835c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be62c89d828631e71c07b16481d1e126",
     "grade": false,
     "grade_id": "1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Decision Trees [4 Points]\n",
    "Draw the decision trees for the following boolean functions. Either use pen and paper and scan/photograph the result or employ your ASCII artist within below.\n",
    "\n",
    "Note: $\\oplus := xor$, that means one of the operands has to be true, while the other one has to be false:\n",
    "\n",
    "|$$\\oplus$$ | $$B$$ | $$\\neg B$$|\n",
    "|:---------|:-----|:---------|\n",
    "|$$A$$      |  f  |    t|\n",
    "|$$\\neg A$$ |  t  |    f|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dba674",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "036b14fec23ad7a705b874c9aaf562d1",
     "grade": false,
     "grade_id": "1a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** $\\neg A \\wedge B$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eba68a36",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9f2836883e282f83c51bd783028777f",
     "grade": true,
     "grade_id": "1a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "             +\n",
    "           /   \\\n",
    "          A    -A\n",
    "          F    /  \\\n",
    "              B   -B\n",
    "              T    F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231e9ea9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46f2e0325b65220ee39dde4986b1a78e",
     "grade": false,
     "grade_id": "1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** $A \\oplus B$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77243e00",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f21396484008856a236c6728d2d44f5",
     "grade": true,
     "grade_id": "1b_answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "               +\n",
    "           /      \\\n",
    "          A        -A\n",
    "        /  \\      /  \\\n",
    "        B   -B   B   -B\n",
    "        T    F   F    T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a2e53",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dd2047cae668a16b2b6da9a50fa9f5b",
     "grade": false,
     "grade_id": "1c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** $A \\vee (B \\wedge C) \\vee (\\neg C \\wedge D)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d07e66e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2af131d635c16e17e405789768f240a",
     "grade": true,
     "grade_id": "1c-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "             +\n",
    "           /   \\\n",
    "          A    -A\n",
    "          T    /  \\\n",
    "              C   -C\n",
    "            / \\    / \\ \n",
    "          B   -B  D   -D\n",
    "          T    F  T    F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164463f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08d555131bd63c4850d4ea6ce7876315",
     "grade": false,
     "grade_id": "1d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**d)** $(A \\rightarrow (B \\wedge \\neg C)) \\vee (A \\wedge B)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd9279b4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21dba1a896d5553904739b917f6da1e6",
     "grade": true,
     "grade_id": "1d-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "             +\n",
    "           /   \\\n",
    "          A    -A\n",
    "        / \\     T\n",
    "       B  -B\n",
    "       T   F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6dee1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "069da1dc67d11d6c788cc9cd620ba8c5",
     "grade": false,
     "grade_id": "2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Entropy and Information Gain [8 Points]\n",
    "\n",
    "In many machine learning applications it is crucial to determine which criterions are necessary for a good classification. Decision trees have those criterions close to the root, imposing an order from significant to less significant criterions. One way to select the most important criterion is to compare its information gain or its entropy to others. The following dataset is a hands-on example for this method.\n",
    "\n",
    "Consider the following attributes with their possible values:\n",
    "\n",
    "  * $raining = \\{yes, no\\}$\n",
    "  * $tired = \\{yes, no\\}$\n",
    "  * $late = \\{yes, no\\}$\n",
    "  * $distance = \\{short, medium, long\\}$\n",
    "\n",
    "And a training data set consisting of those attributes:\n",
    "\n",
    "| #  | raining | tired | late | distance | attend_party |\n",
    "|----|---------|-------|------|----------|--------------|\n",
    "| 1  | yes     | no    | no   | short    | **yes**      |\n",
    "| 2  | yes     | no    | yes  | medium   | **no**       |\n",
    "| 3  | no      | yes   | no   | long     | **no**       |\n",
    "| 4  | yes     | yes   | yes  | short    | **no**       |\n",
    "| 5  | yes     | no    | no   | short    | **yes**      |\n",
    "| 6  | no      | no    | no   | medium   | **yes**      |\n",
    "| 7  | no      | yes   | no   | long     | **no**       |\n",
    "| 8  | yes     | no    | yes  | short    | **no**       |\n",
    "| 9  | yes     | yes   | no   | short    | **yes**      |\n",
    "| 10 | no      | yes   | no   | medium   | **no**       |\n",
    "| 11 | no      | yes   | no   | long     | **no**       |\n",
    "| 12 | no      | yes   | yes  | short    | **no**       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c720f41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d16aa7ec4daf6aed8b7b8c84d68d4d61",
     "grade": false,
     "grade_id": "2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Build the root node of a decision tree from the training samples given in the table above by calculating the information gain for all four attributes (raining, tired, late, distance).\n",
    "\n",
    "$$\\operatorname{Gain}(S,A) = \\operatorname{Entropy}(S) - \\sum_{v \\in \\operatorname{Values}(A)} \\frac{|S_v|}{|S|}\\operatorname{Entropy}(S_v)$$\n",
    "\n",
    "$$\\operatorname{Entropy}(S) = -p_{\\oplus} log_{2} p_{\\oplus} - p_{\\ominus} log_{2} p_{\\ominus}$$\n",
    "\n",
    "$S$ is the set of all data samples. $S_v$ is the subset for which attribute $A$ has value $v$. An example for attribute **tired** with value $yes$ would be:\n",
    "$$|S_{yes}| = 7, S_{yes}:[1+, 6‚àí]$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfcfb1fe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5d13a848d94d3a2552c856f613b1fd2d",
     "grade": true,
     "grade_id": "2a-answer",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Entropie(All) = -4/12*log2(4/12)-8/12*log2(8/12) = 0.91829583405 ~ 0.918\n",
    "\n",
    "Entropie(raining = yes) = -3/6*log2(3/6)-3/6*log2(3/6) = 1 \n",
    "\n",
    "Entropie(raining = no) = -1/6*log2(1/6)-5/6*log2(5/6) = 0.65\n",
    "\n",
    "Entropie(tired = yes) = -1/7*log2(1/7)-6/7*log2(6/7) = 0.59\n",
    "\n",
    "Entropie(tired = no) = -3/5*log2(3/5)-3/5*log2(3/5) = 0.88\n",
    "\n",
    "Entropie(late = yes) = 0/4*log2(0/4)-4/4*log2(4/4) = 0\n",
    "\n",
    "Entropie(late = no) = -4/8*log2(4/8)-4/8*log2(4/8) = 1\n",
    "\n",
    "Entropie(distance = short) = -3/6*log2(3/6)-3/6*log2(3/6) = 1\n",
    "\n",
    "Entropie(distance = long) = -0/3*log2(0/3)-3/3*log2(3/3) = 0\n",
    "\n",
    "Entropie(distance = medium) = -1/3*log2(1/3)-2/3*log2(2/3) = 0.92\n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "Gains(All, raining) = 0.918 - (6/12 * 1 + 6/12*0.65) = 0.093\n",
    "\n",
    "Gains(All, tired) = 0.918 - (7/12 * 0.59 + 5/12*0.88) = 0.21\n",
    "\n",
    "Gains(All, late) = 0.918 - (4/12 * 0 + 8/12 * 1) = 0.25\n",
    "\n",
    "Gains(All, distance) = 0.918 - (6/12 * 1 + 3/12*0 + 3/12*0.92) = 0.188\n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "We should choose late as the root of our tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f9bc2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "462907b7cdb40f8c21a7a10f98f41f3a",
     "grade": false,
     "grade_id": "2b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Perform the same calculation as in **a)** but use the gain ratio instead of the information gain. Does the result for the root node change?\n",
    "\n",
    "$$\\operatorname{GainRatio}(S,A) = \\frac{\\operatorname{Gain}(S,A)}{\\operatorname{SplitInformation}(S,A)}$$\n",
    "\n",
    "$$\\operatorname{SplitInformation}(S,A) = - \\sum_{v \\in \\operatorname{Values}(A)} \\frac{|S_v|}{|S|} \\log_{2} \\frac{|S_{v}|}{|S|}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb2d1628",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c536e75b992639fa2b21877a388eda0f",
     "grade": true,
     "grade_id": "2b-answer",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Splitinformation(All, raining) = -6/12*log2(6/12)-6/12*log2(6/12) = 1\n",
    "\n",
    "Splitinformation(All, tired) = -7/12*log2(7/12)-5/12*log2(5/12) = 0.98\n",
    "\n",
    "Splitinformation(All, late) = -4/12*log2(4/12)-8/12*log2(8/12) = 0.91\n",
    "\n",
    "Splitinformation(All, distance) = -6/12*log2(6/12)-3/12*log2(3/12)-3/12*log2(3/12) = 1.5\n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "GainRatio(All, raining) =  0.093/1 = 0.093\n",
    "\n",
    "GainRatio(All, tired) = 0.21/0.98 = 0.21\n",
    "\n",
    "GainRatio(All, late) = 0.25/0.91 = 0.27\n",
    "\n",
    "GainRatio(All, distance) =  0.188/1.5 = 0.12\n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ebe44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88c5421bdfb62791f686fd966ab0522f",
     "grade": false,
     "grade_id": "3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## ID3 algorithm [4 Points]\n",
    "\n",
    "Implement the following two functions in Python. Take a look at the `assert`s to see how the function should behave. An assert is a condition that your function is required to pass. Most of the conditions here are taken from the lecture slides (ML-03, Slide 12 & 13). Don't worry if you do not get all asserts to pass, just comment the failing ones out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18085a5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6f905d2d0829b495c78bbb9da30d3e4",
     "grade": false,
     "grade_id": "3a-info",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a) Entropy**\n",
    "\n",
    "$$\\operatorname{Entropy}(S) = - \\sum_{i=1...c} p_i \\log_2 p_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16811a7b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f0b2c3e749c80617e180a3e1370cd4d",
     "grade": true,
     "grade_id": "3a-code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "def entropy(s):\n",
    "    \"\"\"\n",
    "    Calculate the entropy for a given target value set.\n",
    "\n",
    "    Args:\n",
    "        s (list): Target classes for specific observations.\n",
    "\n",
    "    Returns:\n",
    "        The entropy of s.\n",
    "    \"\"\"\n",
    "    #an emty varianbler later used to compute the entropy sum\n",
    "    entropy = 0\n",
    "\n",
    "    #for loop representing the sum equation\n",
    "    amount = uniqueAmount(s)\n",
    "\n",
    "    for x in range(len(amount)):\n",
    "        p = amount[x]/len(s)\n",
    "        entropy = entropy + (-p * log2(p))\n",
    "    return entropy\n",
    "\n",
    "def uniqueAmount(s):\n",
    "\n",
    "    #a list of all unique elements in the list\n",
    "    setS = list(set(s))\n",
    "    #an emty list to save the amount of each unique element\n",
    "    amount = []\n",
    "    \n",
    "\n",
    "    #For loop which initialises the amount list\n",
    "    for x in range (len(setS)):\n",
    "        amount.append(0)\n",
    "        \n",
    "    #For loop which compute the amount of occurences for each unique element in the input list\n",
    "    for x in range (len(s)):\n",
    "        for y in range(len(setS)):\n",
    "            if s[x] == setS[y]:\n",
    "                amount[y] = amount[y]+1\n",
    "\n",
    "    return amount\n",
    "        \n",
    "\n",
    "\n",
    "# See ML-03, Slide 12 & 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95261fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epsilon: Account for small computational and rounding erros\n",
    "epsilon = 1e-3\n",
    "assert abs(entropy([1,1,1,0,0,0]) - 1.0) < epsilon\n",
    "assert abs(entropy([1,1,1,1,0,0,0]) - 0.985) < epsilon\n",
    "assert abs(entropy([1,1,1,1,1,1,0]) - 0.592) < epsilon\n",
    "assert abs(entropy([1,1,1,1,1,1,0,0]) - 0.811) < epsilon\n",
    "assert abs(entropy([2,2,1,1,0,0]) - 1.585) < epsilon\n",
    "assert abs(entropy([2,2,2,1,0]) - 1.371) < epsilon\n",
    "assert abs(entropy([2,2,2,0,0]) - 0.971) < epsilon\n",
    "assert abs(entropy(['yes','yes','yes','no','no','no']) - 1.0) < epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb410c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "42f8db6f4c8da24a8d3ba6073241b42b",
     "grade": false,
     "grade_id": "3b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Information Gain\n",
    "\n",
    "$$\\operatorname{Gain}(S,A) = \\operatorname{Entropy}(S) - \\sum_{v \\in \\operatorname{Values}(A)} \\frac{|S_v|}{|S|} \\operatorname{Entropy}(S_v)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "933bb8b1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31e137f20bd024ba579dabce4d97e2c9",
     "grade": true,
     "grade_id": "3b-code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gain(targets, attr_values):\n",
    "    \"\"\"\n",
    "    Calculates the expected reduction in entropy due to sorting on A.\n",
    "\n",
    "    Args:\n",
    "        targets (list): Target classes for observations in attr_values.\n",
    "        attr_values (list): Values of each instance for the respective attribute.\n",
    "\n",
    "    Returns:\n",
    "        The information gain of\n",
    "    \"\"\"\n",
    "    #Entropy of S\n",
    "    entropyTargets = entropy(targets)\n",
    "\n",
    "    #List of unique values which can be taken by the attribute\n",
    "    unique_Attributes = list(set(attr_values))\n",
    "\n",
    "    #List to split the targetvalues by attribute values\n",
    "    list_subvalues = []*len(unique_Attributes)\n",
    "\n",
    "    #List to contain the entropies of each attribute_value\n",
    "    list_subEntropys = []*len(unique_Attributes)\n",
    "\n",
    "    #This for loop looks at the unique values which can be taken and and splites the labelinglist acordingly\n",
    "    for x in range(len(unique_Attributes)):\n",
    "        list_temp = []\n",
    "        for y in range(len(attr_values)): \n",
    "            if unique_Attributes[x] == attr_values[y]:\n",
    "                list_temp.append(targets[y])\n",
    "        list_subvalues.append(list_temp)\n",
    "\n",
    "    #Calculates the entropy for the sublists created above\n",
    "    for x in list_subvalues:\n",
    "        list_subEntropys.append(entropy(x))\n",
    "\n",
    "         \n",
    "\n",
    "    summEntropyAttribute = 0\n",
    "\n",
    "    #calculationg the gains\n",
    "    for x in range(len(list_subvalues)):\n",
    "        summEntropyAttribute = summEntropyAttribute + (len(list_subvalues[x])/len(attr_values)) * list_subEntropys[x]\n",
    "\n",
    "    gains = entropyTargets - summEntropyAttribute\n",
    "\n",
    "    return gains\n",
    "\n",
    "# See ML-03, Slide 12 & 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "71a826fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lists here can each be seen as one column of a table such as the one in assignment 2.\n",
    "# Assert targets would be the last column, while the attribute values are the values of one attribute, here the\n",
    "# example rain and distance\n",
    "assert_targets = [\"no\",\"no\",\"yes\",\"yes\",\"yes\",\"no\",\"yes\",\"no\",\"yes\",\"yes\",\"yes\",\"yes\",\"yes\",\"no\"]\n",
    "assert_attribute_values_1 = [\"yes\", \"yes\",\"yes\",\"yes\",\"no\", \"no\", \"no\", \"yes\", \"no\", \"no\", \"no\",\"yes\", \"no\", \"yes\"]\n",
    "assert_attribute_values_2 = [\"high\",\"low\",\"medium\",\"high\",\"high\",\"medium\",\"low\",\"medium\",\"low\",\"high\",\"high\",\"medium\",\"low\",\"low\"]\n",
    "assert_attribute_values_3 = [0,1,0,0,0,1,1,0,0,0,1,1,0,1]\n",
    "\n",
    "epsilon = 1e-3\n",
    "assert abs(gain(assert_targets, assert_attribute_values_1) - 0.152) < epsilon\n",
    "assert abs(gain(assert_targets, assert_attribute_values_2) - 0.05) < epsilon\n",
    "assert abs(gain(assert_targets, assert_attribute_values_3) - 0.048) < epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e27f8ad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c340e28e5c4f081d5f03c10dc665d5df",
     "grade": false,
     "grade_id": "3c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** ID3\n",
    "\n",
    "In the next two cells we have implemented the ID3 algorithm. It relies on your two functions from above, `entropy` and `gain`. Try to understand what the code does and replace `# YOUR CODE HERE` with meaningful comments describing the respective parts of the code. Do not forget to write the docstring. Though its often annoying, being able to read other peoples code is one of the key skills (and obstacles) in software engineering. So give it a try! Otherwise you are of course welcome to write your own implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4a5fca98",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe4c7159e309684d9b1467a4bd60b776",
     "grade": true,
     "grade_id": "3c-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter, namedtuple\n",
    "\n",
    "\n",
    "class Node(namedtuple('Node', 'label children')):\n",
    "    \"\"\"\n",
    "    A small node representation with a pretty string representation.\n",
    "    \"\"\"\n",
    "    def __str__(self, level=0):\n",
    "        return_str ='{}{!s}\\n'.format(' ' * level * 4, self.label)\n",
    "        for child in self.children:\n",
    "            return_str += child.__str__(level + 1)\n",
    "        return return_str\n",
    "\n",
    "def id3(data, attributes, targets, target_names, attribute_names):\n",
    "    \"\"\"\n",
    "    Recursively calculate a tree of Nodes (fields: label [string], children [list])\n",
    "    using the ID3 algorithm.\n",
    "    # YOUR CODE HERE\n",
    "    \"\"\"\n",
    "\n",
    "    # This if checks weather or not there is any entropy left in the data. If the targetfunktion is the same for every instance it returns the reuslting target[true;false]\n",
    "    if all(target == targets[0] for target in targets):\n",
    "        return Node('Result: {!s}'.format(target_names[targets[0]]), [])\n",
    "\n",
    "    #If there are no attributes left to determin a target, then this if writes the most commen target fro this branche at the bottom\n",
    "    if len(attributes) == 0:       \n",
    "        most_common_idx = Counter(targets).most_common(1)[0][0]\n",
    "        return Node('Result: {!s}'.format(target_names[most_common_idx]), [])\n",
    "\n",
    "    # This pice of code goes throu all availabe attributes left and determens the attribute with the most gain\n",
    "    gains = [gain(targets, [r[attribute] for r in data])\n",
    "             for attribute in attributes]\n",
    "    max_gain_attribute = attributes[gains.index(max(gains))]\n",
    "\n",
    "    # This builds the root node of the current iteration of the recursion\n",
    "    root = Node('Attribute: {!s} (gain {!s})'.format(attribute_names[max_gain_attribute],\n",
    "                                                     round(max(gains), 4)), [])\n",
    "   # For each possible value of the selected attribute, create a child node and recurse\n",
    "    for vi in set(data_sample[max_gain_attribute] for data_sample in data):\n",
    "        #creating the child node\n",
    "        child = Node('Value: {!s}'.format(vi), [])\n",
    "        root.children.append(child)\n",
    "\n",
    "        # Get the indices of the data points with the current attribute value\n",
    "        vi_indices = [idx for idx, data_sample in enumerate(data)\n",
    "                          if data_sample[max_gain_attribute] == vi]\n",
    " \n",
    "        # Get the data and target values for the current attribute value\n",
    "        data_vi = [data[i] for i in vi_indices]\n",
    "        targets_vi = [targets[i] for i in vi_indices]\n",
    "        \n",
    "        # Recurse on the child node with the remaining attributes and data\n",
    "        attributes_vi = [attribute for attribute in attributes if not attribute == max_gain_attribute]\n",
    "       \n",
    "        if data_vi:\n",
    "            #recursion for the child node\n",
    "            child.children.append(\n",
    "                id3(data_vi, attributes_vi, targets_vi, target_names, attribute_names)\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # If there is no data for this attribute value, create a leaf node with the most common target value    \n",
    "            most_common_idx = Counter(targets_vi).most_common(1)[0][0]\n",
    "            label = 'Result: {!s}'.format(target_names[most_common_idx])\n",
    "            child.children.append(Node(label, []))\n",
    "\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e0a9c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "283adee2240e03ad3988aada7a462fd4",
     "grade": false,
     "grade_id": "3d-1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**d)** The algorithm is applied to two data sets. Run those and discuss the differences. For which data set is the ID3 algorithm better suited and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f918c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "394b7a19dc7403ba2196c54ab420e4a4",
     "grade": false,
     "grade_id": "cell-790ca323099344b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First look at the json file in which the party dataset is saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "28301392",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75f77ac5d27fb8fab5a5ca58182913be",
     "grade": false,
     "grade_id": "cell-c651a26268c4fd31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"attributes\": [\n",
      "        \"raining\",\n",
      "        \"tired\",\n",
      "        \"late\",\n",
      "        \"distance\"\n",
      "    ],\n",
      "    \"data\": [\n",
      "        [\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"no\",\n",
      "            \"short\"\n",
      "        ],\n",
      "        [\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"yes\",\n",
      "            \"medium\"\n",
      "        ],\n",
      "        [\n",
      "            \"no\",\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"long\"\n",
      "        ],\n",
      "        [\n",
      "            \"yes\",\n",
      "            \"yes\",\n",
      "            \"yes\",\n",
      "            \"short\"\n",
      "        ],\n",
      "        [\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"no\",\n",
      "            \"short\"\n",
      "        ],\n",
      "        [\n",
      "            \"no\",\n",
      "            \"no\",\n",
      "            \"no\",\n",
      "            \"medium\"\n",
      "        ],\n",
      "        [\n",
      "            \"no\",\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"long\"\n",
      "        ],\n",
      "        [\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"yes\",\n",
      "            \"short\"\n",
      "        ],\n",
      "        [\n",
      "            \"yes\",\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"short\"\n",
      "        ],\n",
      "        [\n",
      "            \"no\",\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"medium\"\n",
      "        ],\n",
      "        [\n",
      "            \"no\",\n",
      "            \"yes\",\n",
      "            \"no\",\n",
      "            \"long\"\n",
      "        ],\n",
      "        [\n",
      "            \"no\",\n",
      "            \"yes\",\n",
      "            \"yes\",\n",
      "            \"short\"\n",
      "        ]\n",
      "    ],\n",
      "    \"target_names\": [\n",
      "        \"yes\",\n",
      "        \"no\"\n",
      "    ],\n",
      "    \"targets\": [\n",
      "        0,\n",
      "        1,\n",
      "        1,\n",
      "        1,\n",
      "        0,\n",
      "        0,\n",
      "        1,\n",
      "        1,\n",
      "        0,\n",
      "        1,\n",
      "        1,\n",
      "        1\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('party.json', 'r') as party_file:\n",
    "    party = json.load(party_file)\n",
    "    \n",
    "print(json.dumps(party, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f4afed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d2d6eb4db5ba15353dbede48c149cf6",
     "grade": false,
     "grade_id": "cell-9cf4012147f12460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We see that the dataset is parsed as a dictionary with four entries:\n",
    "\n",
    "* `attributes`: A list of the attribute names\n",
    "* `data`: A list of the x-data of our samples. Each sample is again a list\n",
    "* `target_names`: A list of the targets, i.e. labels\n",
    "* `targets`: A list of the labels of our samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ed4ed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0635f51b260f64ea62131b9df63d555b",
     "grade": false,
     "grade_id": "3d-2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "This code runs the ID3 algorithm on the party data set which you already know from assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ba1c38e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a15af5d3e50ae1078ab3d147ade95155",
     "grade": false,
     "grade_id": "3d-3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: late (gain 0.2516)\n",
      "    Value: no\n",
      "        Attribute: distance (gain 0.75)\n",
      "            Value: short\n",
      "                Result: yes\n",
      "            Value: medium\n",
      "                Attribute: tired (gain 1.0)\n",
      "                    Value: no\n",
      "                        Result: yes\n",
      "                    Value: yes\n",
      "                        Result: no\n",
      "            Value: long\n",
      "                Result: no\n",
      "    Value: yes\n",
      "        Result: no\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('party.json', 'r') as party_file:\n",
    "    \n",
    "    party = json.load(party_file)\n",
    "\n",
    "# Make sure our gain function handles the data set as expected.\n",
    "epsilon = 1e-3\n",
    "assert abs(gain(party['targets'], [r[2] for r in party['data']]) - 0.252) < epsilon\n",
    "\n",
    "\n",
    "data = party['data']\n",
    "attribute_names = party['attributes']\n",
    "attributes = list(range(len(attribute_names)))\n",
    "targets = party['targets']\n",
    "target_names = party['target_names']\n",
    "\n",
    "\n",
    "# Apply ID3 algorithm\n",
    "tree_party = id3(data, attributes, targets, target_names, attribute_names)\n",
    "\n",
    "print(tree_party)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e469a64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1732eff75495ba30536ae4f76b57fd62",
     "grade": false,
     "grade_id": "3d-4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "This code runs the ID3 algorithm on the famous iris flowers data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e6643640",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1818dc4c9834c168acbec830171d91ad",
     "grade": false,
     "grade_id": "3d-5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: petal length (gain 1.4463)\n",
      "    Value: 6.0\n",
      "        Result: Iris-virginica\n",
      "    Value: 4.3\n",
      "        Result: Iris-versicolor\n",
      "    Value: 6.3\n",
      "        Result: Iris-virginica\n",
      "    Value: 5.0\n",
      "        Attribute: sepal length (gain 0.8113)\n",
      "            Value: 6.7\n",
      "                Result: Iris-versicolor\n",
      "            Value: 5.7\n",
      "                Result: Iris-virginica\n",
      "            Value: 6.0\n",
      "                Result: Iris-virginica\n",
      "            Value: 6.3\n",
      "                Result: Iris-virginica\n",
      "    Value: 1.4\n",
      "        Result: Iris-setosa\n",
      "    Value: 1.2\n",
      "        Result: Iris-setosa\n",
      "    Value: 4.9\n",
      "        Attribute: sepal width (gain 0.971)\n",
      "            Value: 2.5\n",
      "                Result: Iris-versicolor\n",
      "            Value: 2.7\n",
      "                Result: Iris-virginica\n",
      "            Value: 3.0\n",
      "                Result: Iris-virginica\n",
      "            Value: 3.1\n",
      "                Result: Iris-versicolor\n",
      "            Value: 2.8\n",
      "                Result: Iris-virginica\n",
      "    Value: 1.1\n",
      "        Result: Iris-setosa\n",
      "    Value: 3.0\n",
      "        Result: Iris-versicolor\n",
      "    Value: 6.6\n",
      "        Result: Iris-virginica\n",
      "    Value: 1.3\n",
      "        Result: Iris-setosa\n",
      "    Value: 5.2\n",
      "        Result: Iris-virginica\n",
      "    Value: 4.6\n",
      "        Result: Iris-versicolor\n",
      "    Value: 5.6\n",
      "        Result: Iris-virginica\n",
      "    Value: 4.5\n",
      "        Attribute: sepal length (gain 0.5436)\n",
      "            Value: 6.2\n",
      "                Result: Iris-versicolor\n",
      "            Value: 6.0\n",
      "                Result: Iris-versicolor\n",
      "            Value: 4.9\n",
      "                Result: Iris-virginica\n",
      "            Value: 5.4\n",
      "                Result: Iris-versicolor\n",
      "            Value: 5.6\n",
      "                Result: Iris-versicolor\n",
      "            Value: 6.4\n",
      "                Result: Iris-versicolor\n",
      "            Value: 5.7\n",
      "                Result: Iris-versicolor\n",
      "    Value: 6.4\n",
      "        Result: Iris-virginica\n",
      "    Value: 4.7\n",
      "        Result: Iris-versicolor\n",
      "    Value: 3.8\n",
      "        Result: Iris-versicolor\n",
      "    Value: 6.7\n",
      "        Result: Iris-virginica\n",
      "    Value: 5.7\n",
      "        Result: Iris-virginica\n",
      "    Value: 3.3\n",
      "        Result: Iris-versicolor\n",
      "    Value: 3.9\n",
      "        Result: Iris-versicolor\n",
      "    Value: 5.1\n",
      "        Attribute: sepal length (gain 0.5436)\n",
      "            Value: 6.0\n",
      "                Result: Iris-versicolor\n",
      "            Value: 6.3\n",
      "                Result: Iris-virginica\n",
      "            Value: 6.5\n",
      "                Result: Iris-virginica\n",
      "            Value: 6.9\n",
      "                Result: Iris-virginica\n",
      "            Value: 5.8\n",
      "                Result: Iris-virginica\n",
      "            Value: 5.9\n",
      "                Result: Iris-virginica\n",
      "    Value: 5.5\n",
      "        Result: Iris-virginica\n",
      "    Value: 1.6\n",
      "        Result: Iris-setosa\n",
      "    Value: 5.4\n",
      "        Result: Iris-virginica\n",
      "    Value: 4.2\n",
      "        Result: Iris-versicolor\n",
      "    Value: 1.0\n",
      "        Result: Iris-setosa\n",
      "    Value: 3.5\n",
      "        Result: Iris-versicolor\n",
      "    Value: 5.8\n",
      "        Result: Iris-virginica\n",
      "    Value: 1.7\n",
      "        Result: Iris-setosa\n",
      "    Value: 4.1\n",
      "        Result: Iris-versicolor\n",
      "    Value: 4.8\n",
      "        Attribute: sepal length (gain 1.0)\n",
      "            Value: 6.2\n",
      "                Result: Iris-virginica\n",
      "            Value: 6.8\n",
      "                Result: Iris-versicolor\n",
      "            Value: 5.9\n",
      "                Result: Iris-versicolor\n",
      "            Value: 6.0\n",
      "                Result: Iris-virginica\n",
      "    Value: 6.1\n",
      "        Result: Iris-virginica\n",
      "    Value: 3.6\n",
      "        Result: Iris-versicolor\n",
      "    Value: 1.9\n",
      "        Result: Iris-setosa\n",
      "    Value: 4.0\n",
      "        Result: Iris-versicolor\n",
      "    Value: 6.9\n",
      "        Result: Iris-virginica\n",
      "    Value: 3.7\n",
      "        Result: Iris-versicolor\n",
      "    Value: 1.5\n",
      "        Result: Iris-setosa\n",
      "    Value: 5.9\n",
      "        Result: Iris-virginica\n",
      "    Value: 4.4\n",
      "        Result: Iris-versicolor\n",
      "    Value: 5.3\n",
      "        Result: Iris-virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('iris.json', 'r') as iris_file:\n",
    "    iris = json.load(iris_file)\n",
    "\n",
    "# Make sure our gain function handles the data set as expected.\n",
    "epsilon = 1e-3\n",
    "assert abs(gain(iris['targets'], [r[2] for r in iris['data']]) - 1.446) < epsilon\n",
    "\n",
    "data = iris['data']\n",
    "attribute_names = iris['attributes']\n",
    "attributes = list(range(len(attribute_names)))\n",
    "targets = iris['targets']\n",
    "target_names = iris['target_names']\n",
    "\n",
    "# Apply ID3 algorithm\n",
    "tree_iris = id3(data, attributes, targets, target_names, attribute_names)\n",
    "\n",
    "print(tree_iris)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdae7a9b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2e6c4f9c4f123dbe30830eddaa329a5a",
     "grade": true,
     "grade_id": "3d-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "We would arguet that the first data-set is better suited for ide3 because it has a maximum of 3 child nodes per node. The flower set has 8 childnodes after the root. The fewer amount of childnodes helps the generalisation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b122af1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "55d81c0efd3363db327b656815805cec",
     "grade": false,
     "grade_id": "4-1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Decision Trees on Iris Flowers [4 Points]\n",
    "\n",
    "In this exercise we are going to examine and compare two decision trees that were generated from the iris flower data set to classify three variations of Iris flowers. The Iris data set is a classical example of a labeled dataset, i.e. every sample consists of two parts: features and labels. There are four features per sample in this data set (sepal length ($x_1$), sepal width ($x_2$), petal length ($x_3$) and petal width ($x_4$) in cm) and a corresponding label (Iris Setosa, Iris Versicolour, Iris Virginica). These samples are by nature **noisy**, no matter how carefully the measurement was taken - slight deviation from the actual length **cannot be avoided**. We want to learn how the features are related to the label so that we could (in the future) predict the label of a new sample automatically. One way to obtain such a `classifier` is to train a decision tree on the data.\n",
    "\n",
    "Here are two decisions tree generated by the data set. We will now take a closer look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76080b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "730e61df559215aa8d4dd57701074550",
     "grade": false,
     "grade_id": "4-2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Tree 1:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79aa833c",
   "metadata": {},
   "source": [
    "                      +  \n",
    "                      |\n",
    "                      |\n",
    "                      |\n",
    "       x3 < 2.45      |     x3 >= 2.45\n",
    "   +------------------+------------------+\n",
    "   |                                     |\n",
    "   |                        x4 < 1.75    |     x4 >= 1.75\n",
    "   +                           +---------+---------+\n",
    "setosa                         |                   |\n",
    "                               |                   |\n",
    "                     x3 < 4.95 |   x3 >= 4.95      +\n",
    "                        +--------------+       virginica\n",
    "                        |              |\n",
    "                        |              |\n",
    "              x4 < 1.65 | x4 >= 1.65   +\n",
    "                 +------------+    virginica\n",
    "                 |            |\n",
    "                 |            |\n",
    "                 +            +\n",
    "            versicolor    virginica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba90428",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4633aa12103d3890f8c053b45df9ad0c",
     "grade": false,
     "grade_id": "4-4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**Tree 2:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7100e992",
   "metadata": {},
   "source": [
    "                      +\n",
    "                      |\n",
    "                      |\n",
    "                      |\n",
    "       x3 < 2.45      |     x3 >= 2.45\n",
    "   +------------------+------------------+\n",
    "   |                                     |\n",
    "   |                        x4 < 1.75    |     x4 >= 1.75\n",
    "   +                           +---------+---------+\n",
    "setosa                         |                   |\n",
    "                               |                   |\n",
    "                               +                   +\n",
    "                          versicolor           virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed92b6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffcd784b47c90e217848e02ffc378b75",
     "grade": false,
     "grade_id": "4a-1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What does it mean that the features $x1$ and $x2$ do not appear in the decision trees?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ded920da",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "494a7784873d2fc015370f61c0b64eec",
     "grade": true,
     "grade_id": "4a-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "It means that this tree is less complex making it easier to pass, but which makes it more prawn to missclassifiction of known data. Through the lesser complexaty it is more generell meaning that it is able to classifie new data (hopefully) more accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f932c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "277247f94c11865f9544f0fe2c425842",
     "grade": false,
     "grade_id": "4b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** With which method from the lecture might the second tree have been generated from the first one? Explain the procedure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d955e627",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a5a3187f58d0e0e6e9f8d8932ceeed8",
     "grade": true,
     "grade_id": "4b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "Reduced error pruning: As the tree is just cut after depht 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b33cac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9aa2fb79517682bc4d80360baec170b",
     "grade": false,
     "grade_id": "4c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** After training the tree we can calculate the accuracy, i.e. the percentage of the training set that is classified correctly. Although the first tree was trained on the data set until no improvement of the accuracy was possible, its accuracy is *only* 98%. Explain why it is not 100 %"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5fab11e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "602464d5b9d93a8576cf0a4f433c0c9e",
     "grade": true,
     "grade_id": "4c-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "The accuracy is only 98% as the data wa not 100% conclusive leading to atleast one branch which allows for more the one flower to be classified with. The algorithem choose to display the flower with the hight occurencs underer these attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fbcd1d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65bd16338d432abb937b4f859aad840d",
     "grade": false,
     "grade_id": "4d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**d)** Tree 2 only has a 96% accuracy on the training set. Why might this tree still be preferable over tree 1?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3c01936",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c12b2c472831afbdfebf1f5a5820681c",
     "grade": true,
     "grade_id": "4d-answer",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "As stated in a) the second tree is more generell and less computational expensive(even though this is ignoarable on such a small linear scale.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
